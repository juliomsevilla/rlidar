[["r-y-lidar.html", "3 R y LiDAR 3.1 Preparación del entorno de trabajo 3.2 Preparación de los datos 3.3 Análisis de los datos 3.4 Modelo digital del terreno 3.5 Modelo digital de las elevaciones 3.6 Métodos de masa 3.7 Segmentación de árboles", " 3 R y LiDAR 3.1 Preparación del entorno de trabajo A lo largo de este manual haremos uso de varias librerías de R relativas al tratamiento de datos espacial, con especial atención a la librería lidR que sera la herramienta de cabecera. Dado que muchas puede ser que ya estén instaladas en tu computadora, usaremos un pequeño código que permite distinguir si ya lo está y si no es así, procede a instalarla de forma transparente para ti. packages &lt;- c(&quot;lidR&quot;, &quot;sf&quot;, &quot;rgdal&quot;, &quot;dplyr&quot;, &quot;skimr&quot;, &quot;lmtest&quot;) # Instalamos los paquetes que no estén instalados installed_packages &lt;- packages %in% rownames(installed.packages()) if (any(installed_packages == FALSE)) { install.packages(packages[!installed_packages]) } # Cargamos los paquetes invisible(lapply(packages, library, character.only = TRUE)) A continuación crearemos una estructura de carpetas, predefinida, de forma que el trabajo sea lo más sistemático posible. Con ellas creadas, fijamos el directorio de trabajo y procedemos a descargar y descomprimir los datos LiDAR, vectoriales, raster y tabulares de los que disponemos del trabajo de campo y del vuelo LiDAR: dir.create(&quot;c:/curso_lidar/&quot;, showWarnings = FALSE) dir&lt;-&quot;c:/curso_lidar/&quot; setwd(dir) dir.create(&quot;./temp/&quot;, showWarnings = FALSE) dir.create(&quot;./data/&quot;, showWarnings = FALSE) setwd(&quot;./data/&quot;) download.file(&quot;https://raw.githubusercontent.com/juliomsevilla/rlidar/main/data/lidar_data.zip&quot;, destfile = paste(getwd(), &quot;/lidar_data.zip&quot;, sep=&quot;&quot;), method = &quot;curl&quot;, overwrite=TRUE) unzip(paste(getwd(), &quot;/lidar_data.zip&quot;,sep=&quot;&quot;)) setwd(dir) 3.2 Preparación de los datos Para comenzar, si analizamos los tiles LiDAR, estos no vienen proyectados, por lo que procederemos a ello. Para hacerlo de forma rápida y automática usaremos una estructura de control for de forma que si previamente hemos listado todos los ficheros LiDAR a reproyectar, abriremos cada uno de ellos con readLAS()se les asigne la proyección que realmente tienen y se guarden con ella en la carpeta temp con writeLAS. tiles &lt;- list.files(paste(dir, &quot;data/tiles/&quot;, sep=&quot;&quot;), full.names=TRUE) setwd(&quot;./temp/&quot;) getwd() for (file in tiles) { las&lt;-readLAS(file) epsg(las) &lt;- 25830 writeLAS(las, basename(file)) rm(las) } setwd(dir) 3.3 Análisis de los datos La librería lidR,para gestionar grandes cantidades de datos, usa un objeto LAScatalog de modo que el procesamiento de cada tesela LiDAR se hace de forma ordenada. El objeto LAScatalog en realidad contiene las referencias geográficas y cabeceras de los ficheros LiDAR que permite ubicar espacialmente y posteriormente aplicar la mayoría de las funciones de lidR como si se tratara de una sola nube de puntos cargada en la memoria de la computadora. ctg &lt;- readLAScatalog(&quot;./temp/&quot;) ctg plot(ctg) Una vez creado el objeto LAScatalog procedemos a su validación y estudio con el comando las_check: las_check(ctg) La clasificación de los puntos terrestres es un paso importante en el procesamiento de datos de nubes de puntos. La distinción entre puntos de suelo y no permite crear un modelo digital del terreno que posteriormente nos permita normalizar los puntos LiDAR, esto es, pasar de altitudes respecto a un determinado nivel de referencia a alturas o cotas respecto a un cero, que, evidentemente, si hablamos de árboles es lo que más nos puede interesar. Los datos del ejemplo ya vienen clasificados, pero los volveremos a clasificar para demostrar como lo efectúa la librería lidR. En concreto, esta librería usa dos formas de clasificación: pmf() (K. Zhang et al. 2003) y csf() (W. Zhang et al. 2016), cada uno con parámetros característicos que podremos modificar y es uno de los pasos más críticos y complejos del proceso. Una vez que los puntos son clasificados, se asigna el valor de 2 al campo de clasificación del retorno, siguiendo las prescripciones que estandariza la Sociedad Americana de Fotogrametría y Teledetección (ASPRS) para los formatos LAS 1.1, 1.2, 1.3 y 1.4.1 opt_filter(ctg) &lt;- &quot;-drop-scan-angle &#39;&gt;=91&#39;&quot; opt_output_files(ctg) &lt;- paste0(dir,&quot;/temp/&quot;, &quot;{*}_classified&quot;) classified_ctg &lt;- classify_ground(ctg, csf()) 3.4 Modelo digital del terreno Con la nube de puntos clasificada, al menos en puntos de suelo y no, calcularemos el modelo digital del terreno que posteriormente nos permita normalizar la nube de puntos. La librería lidRpermite tres métodos de interpolación de los puntos del suelo con el comando grid_terrain: tin (red de triángulos irregulares), knnidw (distancia inversa ponderada) y kriging, de menor a mayor complejidad y uso de recursos en este orden.2 En nuestro caso, usamos kriging (lidR usa la librería gstat por si deseamos saber más sobre este método de interpolación probabilístico) porque los otros métodos no se pueden usar debido a los pocos puntos de suelo que tenemos. Si usamos algorithm =tin() por ejemplo, observaremos a un error del tipo convexhull debido a que los puntos de suelo con los que contamos en muchos casos están muy separados físicamente. opt_output_files(classified_ctg) &lt;- paste0(dir,&quot;temp/&quot;, &quot;{*}_dtm&quot;) dtm &lt;- grid_terrain(classified_ctg, 1, algorithm = kriging(k = 40), overwrite=TRUE) dtm plot(dtm) 3.5 Modelo digital de las elevaciones # Normalizamos los datos y creamos el modelo digital de elevaciones normalizado opt_output_files(classified_ctg) &lt;- paste0(dir,&quot;/temp/&quot;, &quot;{*}_norm&quot;) ctg_norm &lt;- normalize_height(classified_ctg, dtm) ctg_norm las_check(ctg_norm) opt_filter(ctg_norm) &lt;- &quot;-drop_z_below 0&quot; # Ignoramos los puntos con cota por debajo de cero opt_output_files(ctg_norm) &lt;- paste0(dir,&quot;/temp/&quot;, &quot;{*}_mds&quot;) mdv &lt;- grid_canopy(ctg_norm, 1, pitfree(c(0,2,5,10,15), c(0,1), subcircle = 0.2)) plot(mdv) 3.6 Métodos de masa Para comenzar cargaremos los puntos de muestreo efectuados en campo: opt_filter(ctg_norm) &lt;- &quot;-drop_z_below 0&quot; plots &lt;- st_read(&quot;./data/parc.shp&quot;) plots plot(plots, add = TRUE, col=&quot;red&quot;) Para recortar estas parcelas de la nube de puntos podemos usar el comando plot_metrics (además guardaremos estos recortes para su uso futuro): tiles_norm &lt;- list.files(paste(dir, &quot;temp/&quot;, sep=&quot;&quot;), full.names = TRUE, pattern = &quot;(.*)norm.las$&quot;) ctg_norm &lt;- readLAScatalog(tiles_norm) stats &lt;- plot_metrics(ctg_norm, .stdmetrics_z, plots, radius = 9) head(stats) Cargamos los datos medidos en las parcelas y se lo añadimos a los datos lidar. A continuación realizamos un análisis de correlación entre las variables de la nube de puntos y la futura variable dependiente (en este caso vcc). Se define por correlación a la dirección y magnitud de la asociación entre dos variables cuantitativas, es decir que grado de relación hay entre ellas y si el aumento o disminución de una provoca el aumento o disminución de la otra. El grado de correlación se mide mediante dos coeficientes: el coeficiente de correlación de Pearson y el coeficiente de correlación de Spearman, análogos en significado pero disimiles en su aplicación. El coeficiente de correlación de Pearson es un coeficiente adimensional que va fluctúa entre -1 y +1, donde el primer valor indica la existencia de una asociación perfecta en sentido decreciente y el segundo en sentido creciente. Evidentemente, el valor cero, indica la inexistencia de relación. El coeficiente de correlación de Pearson (a veces conocido como coeficiente de correlación a secas) es aplicable para variables cuantitativas que se relacionan de forma lineal. Por otro lado, el coeficiente de correlación de Spearman, es un evaluador de correlación, homólogo en su valor (-1 a +1) al de Pearson, pero con un carácter no paramétrico, lo que implica que la relación entre las variables puede no ser lineal, que no es tan exigente en la existencia de normalidad en la población y aplicable incluso a variables ordinales. Centrándonos en el coeficiente de correlación de Pearson, dado que tratamos variables cuantitativas, empezamos cargando los datos de volumenes de las parcelas de muestreo, pasando posteriormente a unirlas a la tabla con los estadísticos descriptivos de la nube de puntos de esas parcelas obtenido anteriormente. Para finalizar mostramos las seis variables más relacionadas con la futura variable dependiente. vcc &lt;- readxl::read_excel(&quot;data/muestreo.xlsx&quot;) head(vcc) vcc &lt;- left_join(vcc, stats, by = c(&quot;parc&quot; = &quot;id&quot;)) df &lt;- vcc %&gt;% #select(-c(parc, X, Y))%&gt;% cor()%&gt;% data.frame()%&gt;% add_rownames(var = &quot;lidar_stat&quot;)%&gt;% filter(lidar_stat!=&#39;vcc&#39;)%&gt;% arrange(desc(vcc)) head(df, 3) tail(df, 3) Analizamos la variable dependiente skim(vcc$vcc) shapiro.test(vcc$vcc) plotn &lt;- function(x,main=&quot;Histograma de frecuencias \\ny distribución normal&quot;, xlab=&quot;X&quot;,ylab=&quot;Densidad&quot;) { min &lt;- min(x) max &lt;- max(x) media &lt;- mean(x) dt &lt;- sd(x) hist(x,freq=F,main=main,xlab=xlab,ylab=ylab) curve(dnorm(x,media,dt), min, max,add = T,col=&quot;blue&quot;) } plotn(sqrt(vcc$vcc)) Construimos el modelo lm&lt;-lm(vcc~zq90, data=vcc) summary(lm) plot(vcc$vcc, predict(lm)) abline(0,1) par(mfrow=c(2,2)) plot(lm) par(mfrow=c(1,1)) shapiro.test(residuals(lm)) bptest(lm) Calculamos los estadísticos de los recintos. El radio de nuestras parcelas es de 9 metros, por lo que la superficie es de 254.469004941 m2 y esto implica una resolución de 15.95208 pixel &lt;- sqrt(pi*9^2) metrics &lt;- grid_metrics(ctg_norm, .stdmetrics_z, res = pixel) plot(metrics$zq90) vcc_pred &lt;- -899.025+73.630*metrics$zq90 plot(vcc_pred) writeRaster(vcc_pred, paste(dir, &quot;/temp/&quot;, &quot;vcc_pred.tif&quot;, sep=&quot;&quot;), datatype=&#39;FLT4S&#39;,overwrite = TRUE, bylayer = FALSE) 3.7 Segmentación de árboles opt_output_files(ctg_norm) &lt;- &quot;&quot; ttops &lt;- find_trees(ctg_norm, lmf(4), uniqueness = &quot;bitmerge&quot;) opt_output_files(ctg_norm) &lt;- paste0(dir,&quot;/temp/&quot;, &quot;{*}_segmented&quot;) segm &lt;- dalponte2016(mdv, ttops) ctg_segmented &lt;- segment_trees(ctg_norm, segm) opt_output_files(ctg_segmented) &lt;- &quot;&quot; lasplot &lt;- clip_circle(ctg_segmented, 599358.8984,4734939.2286, 50) #plot(lasplot, color = &quot;treeID&quot;, bg = &quot;white&quot;, size = 4) Referencias "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
